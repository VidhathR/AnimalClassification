{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da6a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the main folder\n",
    "path_to_folder = \"Dataset\"\n",
    "\n",
    "# Loop through all subdirectories inside the main folder\n",
    "for subdir in os.listdir(path_to_folder):\n",
    "\n",
    "    # Define the path to the subdirectory\n",
    "    subdir_path = os.path.join(path_to_folder, subdir)\n",
    "\n",
    "    # Check if the subdirectory is a directory\n",
    "    if os.path.isdir(subdir_path):\n",
    "\n",
    "        # Loop through all image files inside the subdirectory\n",
    "        for file in os.listdir(subdir_path):\n",
    "\n",
    "            # Define the path to the image file\n",
    "            file_path = os.path.join(subdir_path, file)\n",
    "\n",
    "            # Check if the file is an image file\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "\n",
    "                # Read the image file\n",
    "                img = cv2.imread(file_path)\n",
    "\n",
    "                # Apply background removal using the GrabCut algorithm\n",
    "                # ...\n",
    "                mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "                # Define the rectangle containing the object you want to keep\n",
    "                rect = (50,50,450,290)\n",
    "\n",
    "                # Initialize the background and foreground models using the rectangle\n",
    "                bgdModel = np.zeros((1, 65), np.float64)\n",
    "                fgdModel = np.zeros((1, 65), np.float64)\n",
    "            \n",
    "                # Apply the GrabCut algorithm to the image to obtain the new mask\n",
    "                cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "                # Create a new mask with only the foreground pixels set to 1\n",
    "                new_mask = np.where((mask == 1) + (mask == 3), 255, 0).astype('uint8')\n",
    "\n",
    "                # Apply the new mask to the original image\n",
    "                result = cv2.bitwise_and(img, img, mask=new_mask)\n",
    "\n",
    "                # Save the result\n",
    "                cv2.imwrite(file_path, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5a17457",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54401699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85902 images belonging to 158 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_datagen.flow_from_directory('Dataset',target_size = (224,224), batch_size = 32,class_mode = 'categorical',subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb2946ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21405 images belonging to 158 classes.\n"
     ]
    }
   ],
   "source": [
    "test = train_datagen.flow_from_directory('Dataset',target_size = (224,224), batch_size = 32, class_mode = 'categorical',subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a35a531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8d85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = []\n",
    "import os\n",
    "\n",
    "# Define the directory path\n",
    "directory_path = 'Dataset'\n",
    "\n",
    "# Get a list of all folders in the directory\n",
    "folders = [f for f in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, f))]\n",
    "\n",
    "# Print the folder names\n",
    "for folder in folders:\n",
    "    class_names.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba937667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 157, 157, 157])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6a67735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d6eaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,158):\n",
    "    num.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7096a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(class_names)):\n",
    "    if class_names[i].startswith(\"n\"):\n",
    "        class_names[i] = class_names[i][10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b8ae523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,60):\n",
    "    class_names[i] = class_names[i][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea213e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b5b0e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black_footed_Albatross',\n",
       " 'Laysan_Albatross',\n",
       " 'Sooty_Albatross',\n",
       " 'Groove_billed_Ani',\n",
       " 'Crested_Auklet',\n",
       " 'Least_Auklet',\n",
       " 'Parakeet_Auklet',\n",
       " 'Rhinoceros_Auklet',\n",
       " 'Brewer_Blackbird',\n",
       " 'Red_winged_Blackbird',\n",
       " 'Rusty_Blackbird',\n",
       " 'Yellow_headed_Blackbird',\n",
       " 'Bobolink',\n",
       " 'Indigo_Bunting',\n",
       " 'Lazuli_Bunting',\n",
       " 'Painted_Bunting',\n",
       " 'Cardinal',\n",
       " 'Spotted_Catbird',\n",
       " 'Gray_Catbird',\n",
       " 'Yellow_breasted_Chat',\n",
       " 'Eastern_Towhee',\n",
       " 'Chuck_will_Widow',\n",
       " 'Brandt_Cormorant',\n",
       " 'Red_faced_Cormorant',\n",
       " 'Pelagic_Cormorant',\n",
       " 'Bronzed_Cowbird',\n",
       " 'Shiny_Cowbird',\n",
       " 'Brown_Creeper',\n",
       " 'American_Crow',\n",
       " 'Fish_Crow',\n",
       " 'Black_billed_Cuckoo',\n",
       " 'Mangrove_Cuckoo',\n",
       " 'Yellow_billed_Cuckoo',\n",
       " 'Gray_crowned_Rosy_Finch',\n",
       " 'Purple_Finch',\n",
       " 'Northern_Flicker',\n",
       " 'Acadian_Flycatcher',\n",
       " 'Great_Crested_Flycatcher',\n",
       " 'Least_Flycatcher',\n",
       " 'Olive_sided_Flycatcher',\n",
       " 'Scissor_tailed_Flycatcher',\n",
       " 'Vermilion_Flycatcher',\n",
       " 'Yellow_bellied_Flycatcher',\n",
       " 'Frigatebird',\n",
       " 'Northern_Fulmar',\n",
       " 'Gadwall',\n",
       " 'American_Goldfinch',\n",
       " 'European_Goldfinch',\n",
       " 'Boat_tailed_Grackle',\n",
       " 'Eared_Grebe',\n",
       " 'Horned_Grebe',\n",
       " 'Pied_billed_Grebe',\n",
       " 'Western_Grebe',\n",
       " 'Blue_Grosbeak',\n",
       " 'Evening_Grosbeak',\n",
       " 'Pine_Grosbeak',\n",
       " 'Rose_breasted_Grosbeak',\n",
       " 'Pigeon_Guillemot',\n",
       " 'California_Gull',\n",
       " 'Glaucous_winged_Gull',\n",
       " 'Abyssinian',\n",
       " 'American Bobtail',\n",
       " 'American Curl',\n",
       " 'American Shorthair',\n",
       " 'American Wirehair',\n",
       " 'Applehead Siamese',\n",
       " 'Balinese',\n",
       " 'Bengal',\n",
       " 'Birman',\n",
       " 'Bombay',\n",
       " 'British Shorthair',\n",
       " 'Burmese',\n",
       " 'Burmilla',\n",
       " 'Calico',\n",
       " 'Canadian Hairless',\n",
       " 'Chartreux',\n",
       " 'Chausie',\n",
       " 'Chinchilla',\n",
       " 'Cornish Rex',\n",
       " 'Cymric',\n",
       " 'Devon Rex',\n",
       " 'Dilute Calico',\n",
       " 'Dilute Tortoiseshell',\n",
       " 'Domestic Long Hair',\n",
       " 'Domestic Medium Hair',\n",
       " 'Domestic Short Hair',\n",
       " 'Egyptian Mau',\n",
       " 'Exotic Shorthair',\n",
       " 'Extra-Toes Cat - Hemingway Polydactyl',\n",
       " 'Havana',\n",
       " 'Himalayan',\n",
       " 'Japanese Bobtail',\n",
       " 'Javanese',\n",
       " 'Korat',\n",
       " 'LaPerm',\n",
       " 'Maine Coon',\n",
       " 'Manx',\n",
       " 'Munchkin',\n",
       " 'Chihuahua',\n",
       " 'Japanese_spaniel',\n",
       " 'Maltese_dog',\n",
       " 'Pekinese',\n",
       " 'Shih-Tzu',\n",
       " 'Blenheim_spaniel',\n",
       " 'papillon',\n",
       " 'toy_terrier',\n",
       " 'Rhodesian_ridgeback',\n",
       " 'Afghan_hound',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'Walker_hound',\n",
       " 'English_foxhound',\n",
       " 'redbone',\n",
       " 'borzoi',\n",
       " 'Irish_wolfhound',\n",
       " 'Italian_greyhound',\n",
       " 'whippet',\n",
       " 'Ibizan_hound',\n",
       " 'Norwegian_elkhound',\n",
       " 'otterhound',\n",
       " 'Saluki',\n",
       " 'Scottish_deerhound',\n",
       " 'Weimaraner',\n",
       " 'Staffordshire_bullterrier',\n",
       " 'American_Staffordshire_terrier',\n",
       " 'Bedlington_terrier',\n",
       " 'Border_terrier',\n",
       " 'Kerry_blue_terrier',\n",
       " 'Irish_terrier',\n",
       " 'Norfolk_terrier',\n",
       " 'Norwich_terrier',\n",
       " 'Yorkshire_terrier',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'Lakeland_terrier',\n",
       " 'Sealyham_terrier',\n",
       " 'Airedale',\n",
       " 'cairn',\n",
       " 'Australian_terrier',\n",
       " 'Dandie_Dinmont',\n",
       " 'Boston_bull',\n",
       " 'miniature_schnauzer',\n",
       " 'giant_schnauzer',\n",
       " 'standard_schnauzer',\n",
       " 'Scotch_terrier',\n",
       " 'Tibetan_terrier',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'West_Highland_white_terrier',\n",
       " 'Lhasa',\n",
       " 'flat-coated_retriever',\n",
       " 'curly-coated_retriever',\n",
       " 'golden_retriever',\n",
       " 'Labrador_retriever',\n",
       " 'Chesapeake_Bay_retriever',\n",
       " 'German_short-haired_pointer',\n",
       " 'vizsla']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d31fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_map = dict(zip(num,class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0bd38f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laysan_Albatross'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ce00c4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "3/3 [==============================] - 3s 681ms/step - loss: 4.6976 - accuracy: 0.0208\n",
      "Epoch 2/9\n",
      "3/3 [==============================] - 2s 672ms/step - loss: 4.3492 - accuracy: 0.2500\n",
      "Epoch 3/9\n",
      "3/3 [==============================] - 2s 672ms/step - loss: 3.9858 - accuracy: 0.5625\n",
      "Epoch 4/9\n",
      "3/3 [==============================] - 2s 667ms/step - loss: 4.0741 - accuracy: 0.4688\n",
      "Epoch 5/9\n",
      "3/3 [==============================] - 2s 673ms/step - loss: 4.1703 - accuracy: 0.5104\n",
      "Epoch 6/9\n",
      "3/3 [==============================] - 2s 684ms/step - loss: 3.9826 - accuracy: 0.4583\n",
      "Epoch 7/9\n",
      "3/3 [==============================] - 2s 675ms/step - loss: 3.7348 - accuracy: 0.5104\n",
      "Epoch 8/9\n",
      "3/3 [==============================] - 2s 694ms/step - loss: 3.8618 - accuracy: 0.4167\n",
      "Epoch 9/9\n",
      "3/3 [==============================] - 2s 670ms/step - loss: 3.0226 - accuracy: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d15c167dc0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the input shape and number of classes\n",
    "img_height, img_width = 224, 224\n",
    "num_classes = 158\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(train,steps_per_epoch = 3,epochs= 9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "338278ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "67e6f9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - 223s 334ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4954449894884373"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(test)\n",
    "r = np.argmax(result, axis=-1)\n",
    "mc.accuracy_score(test.classes,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d4dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
